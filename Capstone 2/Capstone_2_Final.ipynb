{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "161939bb-562e-498a-a0ec-be7ef2401c19",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue;\"><b>INTRODUCTION</b></h1>\n",
    "Data Scientist and Data Analyst jobs require a specialized set of skills. I want to identify the most in demand skills in the Glassdoor job descriptions for a Data Scientist and Data Analyst, so I know which ones  to focus on developing first to be a more highly rated candidate during my job search. Understanding where these jobs are located and in which industries will allow me to more efficiently focus my search in the appropriate state and industry to increase my odds of getting a job as a Data Scientist or Data Analyst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba55f6e8-81e2-4299-a8d3-8835324b7dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries for project.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "382be177-4c01-48f2-a39b-cb3f99f2df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from .CSV\n",
    "df = pd.read_csv('/Users/johnharmer/Desktop/Data_Science_Job_Skills/Capstone 2/glassdoor_jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0a390ec-944a-4548-bf3a-9a16c8dbe44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>-1</td>\n",
       "      <td>Job Overview\\nA Data Scientist at ExploreLearn...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Cambium Learning Group\\n4.3</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>2004</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Primary &amp; Secondary Schools</td>\n",
       "      <td>Education</td>\n",
       "      <td>$500 million to $1 billion (USD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024 University Graduate - Data Scientist</td>\n",
       "      <td>Employer Provided Salary:$83K - $153K</td>\n",
       "      <td>Our Company\\n\\nChanging the world through digi...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Adobe\\n4.4</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1982</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Computer Hardware Development</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$5 to $10 billion (USD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist – Entry Level 2024</td>\n",
       "      <td>Employer Provided Salary:$71K - $133K</td>\n",
       "      <td>Introduction\\nRanked by Forbes as one of the w...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>IBM\\n3.9</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1911</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>Employer Provided Salary:$94K - $183K</td>\n",
       "      <td>The Microsoft 365 team is looking for a Data S...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Microsoft\\n4.3</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1975</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Computer Hardware Development</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entry Level Data Scientist 2023/2024</td>\n",
       "      <td>$48K - $78K (Glassdoor est.)</td>\n",
       "      <td>You may not realize it, but you’ve likely used...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>CPChem\\n3.9</td>\n",
       "      <td>The Woodlands, TX</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>2000</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Chemical Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job Title  \\\n",
       "0                             Data Scientist   \n",
       "1  2024 University Graduate - Data Scientist   \n",
       "2          Data Scientist – Entry Level 2024   \n",
       "3                           Data Scientist 2   \n",
       "4       Entry Level Data Scientist 2023/2024   \n",
       "\n",
       "                         Salary Estimate  \\\n",
       "0                                     -1   \n",
       "1  Employer Provided Salary:$83K - $153K   \n",
       "2  Employer Provided Salary:$71K - $133K   \n",
       "3  Employer Provided Salary:$94K - $183K   \n",
       "4           $48K - $78K (Glassdoor est.)   \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "0  Job Overview\\nA Data Scientist at ExploreLearn...     4.2   \n",
       "1  Our Company\\n\\nChanging the world through digi...     4.4   \n",
       "2  Introduction\\nRanked by Forbes as one of the w...     3.9   \n",
       "3  The Microsoft 365 team is looking for a Data S...     4.3   \n",
       "4  You may not realize it, but you’ve likely used...     3.9   \n",
       "\n",
       "                  Company Name           Location                    Size  \\\n",
       "0  Cambium Learning Group\\n4.3             Remote  1001 to 5000 Employees   \n",
       "1                   Adobe\\n4.4       San Jose, CA        10000+ Employees   \n",
       "2                     IBM\\n3.9        Atlanta, GA        10000+ Employees   \n",
       "3               Microsoft\\n4.3        Redmond, WA        10000+ Employees   \n",
       "4                  CPChem\\n3.9  The Woodlands, TX  1001 to 5000 Employees   \n",
       "\n",
       "   Founded  Type of ownership                                 Industry  \\\n",
       "0     2004  Company - Private              Primary & Secondary Schools   \n",
       "1     1982   Company - Public            Computer Hardware Development   \n",
       "2     1911   Company - Public  Information Technology Support Services   \n",
       "3     1975   Company - Public            Computer Hardware Development   \n",
       "4     2000  Company - Private                   Chemical Manufacturing   \n",
       "\n",
       "                   Sector                           Revenue  \n",
       "0               Education  $500 million to $1 billion (USD)  \n",
       "1  Information Technology           $5 to $10 billion (USD)  \n",
       "2  Information Technology                $10+ billion (USD)  \n",
       "3  Information Technology                $10+ billion (USD)  \n",
       "4           Manufacturing                $10+ billion (USD)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26792a8e-1745-4fe4-9c08-4741287b64f6",
   "metadata": {},
   "source": [
    "<h3 style=\"color: blue;\"><b>DATA CLEANING</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7c21b97-24ca-43ec-9ce8-99a55bbe5967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter job titles for 'Data Scientist' or 'Data Analyst'\n",
    "df_filtered = df[df['Job Title'].str.contains('Data Scientist|Data Analyst', case=False, na=False)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1567b571-12ce-484d-a6e2-a0bbdc70eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter job titles for 'Data Scientist' or 'Data Analyst'\n",
    "df_filtered.loc[:, 'State'] = df_filtered['Location'].apply(\n",
    "    lambda x: 'Remote' if 'remote' in x.lower() else x.split(',')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2dc86d2-6235-48fb-bdd9-3668492273ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the state from the Location column, treating \"Remote\" as its own category\n",
    "df_filtered['State'] = df_filtered['Location'].apply(lambda x: 'Remote' if 'remote' in x.lower() else x.split(',')[-1].strip())\n",
    "\n",
    "# Mapping of full state names to their 2-letter abbreviations\n",
    "state_abbrev = {\n",
    "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA', 'Colorado': 'CO', \n",
    "    'Connecticut': 'CT', 'Delaware': 'DE', 'District of Columbia': 'DC', 'Florida': 'FL', 'Georgia': 'GA', \n",
    "    'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS', \n",
    "    'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA', \n",
    "    'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT', \n",
    "    'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', \n",
    "    'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', \n",
    "    'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD', \n",
    "    'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', \n",
    "    'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "# Function to map full state names to abbreviations\n",
    "def map_state_to_abbreviation(state):\n",
    "    state = state.strip()\n",
    "    if state in state_abbrev:\n",
    "        return state_abbrev[state]\n",
    "    return state\n",
    "\n",
    "# Drop unwanted entries\n",
    "df_filtered = df_filtered[~df_filtered['State'].isin(['United States', '-1', 'Point Loma', 'New York State', 'Manhattan'])]\n",
    "\n",
    "# Apply the state abbreviation mapping (keeping 'Remote' as is)\n",
    "df_filtered['State'] = df_filtered['State'].apply(lambda x: x if x == 'Remote' else map_state_to_abbreviation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0307dcf-6bbc-4fcd-a195-558debef31e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>-1</td>\n",
       "      <td>Job Overview\\nA Data Scientist at ExploreLearn...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Cambium Learning Group\\n4.3</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>2004</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Primary &amp; Secondary Schools</td>\n",
       "      <td>Education</td>\n",
       "      <td>$500 million to $1 billion (USD)</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024 University Graduate - Data Scientist</td>\n",
       "      <td>Employer Provided Salary:$83K - $153K</td>\n",
       "      <td>Our Company\\n\\nChanging the world through digi...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Adobe\\n4.4</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1982</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Computer Hardware Development</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$5 to $10 billion (USD)</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist – Entry Level 2024</td>\n",
       "      <td>Employer Provided Salary:$71K - $133K</td>\n",
       "      <td>Introduction\\nRanked by Forbes as one of the w...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>IBM\\n3.9</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1911</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>Employer Provided Salary:$94K - $183K</td>\n",
       "      <td>The Microsoft 365 team is looking for a Data S...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Microsoft\\n4.3</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1975</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Computer Hardware Development</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entry Level Data Scientist 2023/2024</td>\n",
       "      <td>$48K - $78K (Glassdoor est.)</td>\n",
       "      <td>You may not realize it, but you’ve likely used...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>CPChem\\n3.9</td>\n",
       "      <td>The Woodlands, TX</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>2000</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Chemical Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job Title  \\\n",
       "0                             Data Scientist   \n",
       "1  2024 University Graduate - Data Scientist   \n",
       "2          Data Scientist – Entry Level 2024   \n",
       "3                           Data Scientist 2   \n",
       "4       Entry Level Data Scientist 2023/2024   \n",
       "\n",
       "                         Salary Estimate  \\\n",
       "0                                     -1   \n",
       "1  Employer Provided Salary:$83K - $153K   \n",
       "2  Employer Provided Salary:$71K - $133K   \n",
       "3  Employer Provided Salary:$94K - $183K   \n",
       "4           $48K - $78K (Glassdoor est.)   \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "0  Job Overview\\nA Data Scientist at ExploreLearn...     4.2   \n",
       "1  Our Company\\n\\nChanging the world through digi...     4.4   \n",
       "2  Introduction\\nRanked by Forbes as one of the w...     3.9   \n",
       "3  The Microsoft 365 team is looking for a Data S...     4.3   \n",
       "4  You may not realize it, but you’ve likely used...     3.9   \n",
       "\n",
       "                  Company Name           Location                    Size  \\\n",
       "0  Cambium Learning Group\\n4.3             Remote  1001 to 5000 Employees   \n",
       "1                   Adobe\\n4.4       San Jose, CA        10000+ Employees   \n",
       "2                     IBM\\n3.9        Atlanta, GA        10000+ Employees   \n",
       "3               Microsoft\\n4.3        Redmond, WA        10000+ Employees   \n",
       "4                  CPChem\\n3.9  The Woodlands, TX  1001 to 5000 Employees   \n",
       "\n",
       "   Founded  Type of ownership                                 Industry  \\\n",
       "0     2004  Company - Private              Primary & Secondary Schools   \n",
       "1     1982   Company - Public            Computer Hardware Development   \n",
       "2     1911   Company - Public  Information Technology Support Services   \n",
       "3     1975   Company - Public            Computer Hardware Development   \n",
       "4     2000  Company - Private                   Chemical Manufacturing   \n",
       "\n",
       "                   Sector                           Revenue   State  \n",
       "0               Education  $500 million to $1 billion (USD)  Remote  \n",
       "1  Information Technology           $5 to $10 billion (USD)      CA  \n",
       "2  Information Technology                $10+ billion (USD)      GA  \n",
       "3  Information Technology                $10+ billion (USD)      WA  \n",
       "4           Manufacturing                $10+ billion (USD)      TX  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d4280b-5a55-4d31-b7ae-6c0d74e1bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common skills, technologies, and software to look for in job descriptions\n",
    "skills_list = ['Python', 'SQL', 'Excel', 'R', 'Tableau', 'Power BI', 'Machine Learning', \n",
    "               'Deep Learning', 'Statistics', 'Data Mining', 'Hadoop', 'Spark', \n",
    "               'TensorFlow', 'Keras', 'scikit-learn', 'NLP', 'AWS', 'Azure', 'Cloud', 'Data Analysis']\n",
    "\n",
    "# Define a function to extract skills from the job descriptions\n",
    "def extract_skills(description):\n",
    "    found_skills = set()\n",
    "    for skill in skills_list:\n",
    "        if re.search(r'\\b' + re.escape(skill) + r'\\b', description, re.IGNORECASE):\n",
    "            found_skills.add(skill)\n",
    "    return ', '.join(found_skills)\n",
    "\n",
    "# Apply the function to the Job Description column and create a new 'Extracted Skills' column\n",
    "df_filtered['Extracted Skills'] = df_filtered['Job Description'].apply(extract_skills)\n",
    "\n",
    "# Display the updated dataframe with the new 'Extracted Skills' column\n",
    "print(df_filtered[['Job Title', 'State', 'Extracted Skills']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f63f7c0-20fb-4d98-b2a4-1845c3cff0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the extracted skills into one list\n",
    "all_skills = df_filtered['Extracted Skills'].str.split(', ').explode()\n",
    "\n",
    "# Count the occurrences of each skill\n",
    "skill_counts = Counter(all_skills)\n",
    "\n",
    "# Convert the Counter object to a DataFrame for easier plotting\n",
    "skills_df = pd.DataFrame(skill_counts.items(), columns=['Skill', 'Count']).sort_values(by='Count', ascending=False)\n",
    "\n",
    "# Display the skill counts to the user\n",
    "print(skills_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c5192-56fa-43e7-b5b7-76e0a859ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty skill entries and plot the skill counts\n",
    "skills_df = skills_df[skills_df['Skill'] != '']\n",
    "\n",
    "# Create bar plot to show Skills count\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(skills_df['Skill'], skills_df['Count'], color='skyblue')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Skill')\n",
    "plt.title('Skill Frequency in Job Descriptions')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeaf7f4-1dc5-4f03-a29a-475b467b960b",
   "metadata": {},
   "source": [
    "<b><h3>Most In-Demand Skills</b></h3>\n",
    "<b>Top 15 Skills:</b> Machine Learning, Python, Statistics, R, Data Analysis, Data Mining, SQL, Cloud, Tableau, NLP, Excel, Deep Learning, Spark, TensorFlow, AWS<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ab613-9179-48e2-b037-9f654c822218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many unique job titles are in the df.\n",
    "job_titles = df['Job Title'].value_counts()\n",
    "print(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded8178-0b58-443d-a8f7-c824713e496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of 'Data Scientist' and 'Data Analyst' separately\n",
    "data_scientist_count = df_filtered['Job Title'].str.contains('Data Scientist', case=False, na=False).sum()\n",
    "data_analyst_count = df_filtered['Job Title'].str.contains('Data Analyst', case=False, na=False).sum()\n",
    "\n",
    "# Display counts\n",
    "print(data_scientist_count, data_analyst_count)\n",
    "\n",
    "# Create a DataFrame to hold the counts for plotting\n",
    "job_title_data = pd.DataFrame({\n",
    "    'Job Title': ['Data Scientist', 'Data Analyst'],\n",
    "    'Count': [data_scientist_count, data_analyst_count]})\n",
    "\n",
    "# Create a bar plot to visualize the counts\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(job_title_data['Job Title'], job_title_data['Count'], color=['skyblue', 'lightgreen'])\n",
    "plt.ylabel('Number of Positions')\n",
    "plt.title('Count of Job Titles Containing \"Data Scientist\" or \"Data Analyst\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033de1f-8f5a-4e74-bb8e-eb3f2969bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique industries in the df_filtered.\n",
    "unique_industries_count = df_filtered['Industry'].nunique()\n",
    "\n",
    "unique_industries_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5676067-bb13-4508-8076-3b676233bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each Industry.\n",
    "unique_industries_count = df_filtered['Industry'].value_counts()\n",
    "unique_industries_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcaaf0d-8402-4ee6-8f3e-7e24f9fb32dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove industries where the value is '-1'\n",
    "industry_counts_cleaned = unique_industries_count[unique_industries_count.index != '-1']\n",
    "\n",
    "# Print the cleaned industry counts with the industry names as the index\n",
    "print(industry_counts_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449678e-b656-429e-ab96-30f118062244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the counts of each industry to help identify which industry is more likely to be hiring.\n",
    "plt.figure(figsize=(10, 10))\n",
    "industry_counts_cleaned.plot(kind='barh', color='lightblue')\n",
    "plt.xlabel('Number of Positions')\n",
    "plt.ylabel('Industry')\n",
    "plt.title('Industry Hiring Counts')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for readability\n",
    "plt.grid(True, which='both', axis='both', linestyle='--', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3398000a-b3c7-4240-b9dd-53e61dfe818a",
   "metadata": {},
   "source": [
    "<b><h3>RESULTS</b></h3>\n",
    "1226 jobs with job titles containing Data Scientist(1192) or Data Analyst(32).<br>\n",
    "\n",
    "<b><h4>Top Industries Hiring:</b></h4>\n",
    "Information Technology, Finance, Healthcare, Enterprise Software & Network Solutions, Aerospace & Defense.\n",
    "IT support services has the most job openings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fafd8-6cca-481f-8519-dd7c53956358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many jobs are located in each state, including remote positions\n",
    "jobs_by_state = df_filtered['State'].value_counts()\n",
    "\n",
    "# Display the results using standard print\n",
    "print(jobs_by_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a13e45-a4ab-423e-8013-79a50ae6823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart to show job counts by state\n",
    "plt.figure(figsize=(10, 8))\n",
    "jobs_by_state.plot(kind='barh', color='skyblue')\n",
    "plt.xlabel('Number of Jobs')\n",
    "plt.ylabel('State')\n",
    "plt.title('Job Counts by State')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for readability\n",
    "plt.grid(True, which='both', axis='both', linestyle='--', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff7ac19-49c6-4500-98c2-1e29ae258520",
   "metadata": {},
   "source": [
    "<h3><B>Top 10 states with job openings</B></h3>\n",
    "Remote    218<br>\n",
    "CA        195<br>\n",
    "VA        105<br>\n",
    "TX         77<br>\n",
    "NJ         77<br>\n",
    "MA         59<br>\n",
    "CO         39<br>\n",
    "PA         38<br>\n",
    "NC         36<br>\n",
    "MI         30<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e26724-6b55-4740-98fe-9e6158cda1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and parse the salary column data\n",
    "def clean_salary(salary):\n",
    "    if 'K' in salary:\n",
    "        salary = salary.replace('K', '').replace('$', '').replace('Employer Provided Salary:', '').replace('(Glassdoor est.)', '').strip()\n",
    "        if '-' in salary:\n",
    "            # Split into minimum and maximum salary and compute the average\n",
    "            min_salary, max_salary = salary.split('-')\n",
    "            avg_salary = (int(min_salary) + int(max_salary)) / 2\n",
    "            return avg_salary\n",
    "        else:\n",
    "            # Single salary value\n",
    "            return float(salary.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f68bce-af68-404a-86e1-d1839d7f9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the clean_salary function to the Salary Estimate column\n",
    "df_filtered['Avg Salary'] = df_filtered['Salary Estimate'].apply(clean_salary)\n",
    "\n",
    "# Fill NaNs with a placeholder value (e.g., 0) and convert to integers\n",
    "df_filtered['Avg Salary'].fillna(0, inplace=True)\n",
    "df_filtered['Avg Salary'] = df_filtered['Avg Salary'].astype(int)\n",
    "\n",
    "# Display 'Salary Estimate' and 'Avg Salary' to confirm.\n",
    "df_filtered[['Salary Estimate', 'Avg Salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d885ac4b-080c-4c00-bb39-1e93c3eec17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert revenue to integer\n",
    "def convert_to_integer(value):\n",
    "    if 'M' in value:\n",
    "        return int(float(value.replace('M', '').replace('+', '').replace('Less than ', '0.')) * 1e6)\n",
    "    elif 'B' in value:\n",
    "        return int(float(value.replace('B', '').replace('+', '').replace('Less than ', '0.')) * 1e9)\n",
    "    return int(value.replace('+', '').replace('Less than ', '0.'))\n",
    "\n",
    "# Function to parse and clean the revenue data with handling for mixed units and special cases\n",
    "def parse_revenue(revenue):\n",
    "    if 'Unknown' in revenue or 'Non-Applicable' in revenue:\n",
    "        return None\n",
    "    revenue = revenue.replace('(USD)', '').replace('$', '').replace(' million', 'M').replace(' billion', 'B').strip()\n",
    "    if ' to ' in revenue:\n",
    "        revenue_range = revenue.split(' to ')\n",
    "        if 'M' in revenue_range[0] and 'B' in revenue_range[1]:\n",
    "            min_revenue = float(revenue_range[0].replace('M', '').replace('+', '').replace('Less than ', '0.')) * 1e6\n",
    "            max_revenue = float(revenue_range[1].replace('B', '').replace('+', '').replace('Less than ', '0.')) * 1e9\n",
    "        elif 'B' in revenue_range[0] and 'M' in revenue_range[1]:\n",
    "            min_revenue = float(revenue_range[0].replace('B', '').replace('+', '').replace('Less than ', '0.')) * 1e9\n",
    "            max_revenue = float(revenue_range[1].replace('M', '').replace('+', '').replace('Less than ', '0.')) * 1e6\n",
    "        else:\n",
    "            min_revenue = convert_to_integer(revenue_range[0])\n",
    "            max_revenue = convert_to_integer(revenue_range[1])\n",
    "        return (min_revenue, max_revenue)\n",
    "    elif 'M' in revenue or 'B' in revenue:\n",
    "        revenue = convert_to_integer(revenue)\n",
    "        return (revenue, revenue)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e6217-1ec4-418b-b680-4ea96fee185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the parsing function to the Revenue column\n",
    "df_filtered['parsed_revenue'] = df_filtered['Revenue'].apply(parse_revenue)\n",
    "\n",
    "df_filtered['parsed_revenue'] = df_filtered['Revenue'].apply(parse_revenue)\n",
    "\n",
    "# Extract min and max revenue\n",
    "df_filtered['Min Revenue'] = df_filtered['parsed_revenue'].apply(lambda x: x[0] if x is not None else None)\n",
    "df_filtered['Max Revenue'] = df_filtered['parsed_revenue'].apply(lambda x: x[1] if x is not None else None)\n",
    "\n",
    "# Drop the parsed_revenue column\n",
    "df_filtered.drop(columns=['parsed_revenue'], inplace=True)\n",
    "\n",
    "# Display the cleaned revenue ranges\n",
    "df_filtered[['Revenue', 'Min Revenue', 'Max Revenue']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432954e9-1d50-42c3-ac71-1df6b572e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics for numerical features\n",
    "summary_stats_numerical = df_filtered.describe()\n",
    "\n",
    "# Display summary statistics for categorical features\n",
    "summary_stats_categorical = df_filtered.describe(include=['O'])\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df_filtered.isnull().sum()\n",
    "\n",
    "summary_stats_numerical, summary_stats_categorical, missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1650bb3-4499-4650-ad9e-eaade768e013",
   "metadata": {},
   "source": [
    "<b><h3>Inferential Statistics</b></h3>\n",
    "<B>Hypotheses:</B><br>\n",
    "<b>H0 (Null Hypothesis):</b> There is no significant difference in the average salary estimate between industries.<br>\n",
    "<b>H1 (Alternative Hypothesis):</b> There is a significant difference in the average salary estimate between industries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdb066b-92b2-47ff-880f-da7dd9e4d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of average salary estimate vs. industry\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.scatterplot(data=df_filtered, x='Industry', y='Avg Salary')\n",
    "plt.title('Relationship Between Avg Salary Estimate and Industry')\n",
    "plt.xlabel('Industry')\n",
    "plt.ylabel('Avg Salary Estimate')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d91c654-981d-4051-a2ce-241d300b119e",
   "metadata": {},
   "source": [
    "Companies from the internet and software industires tend to pay higher wages. That being said, most of the industires are paying ~$100K or more for Data Scientist and Data Analyst jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de87219d-90c4-4a75-ac45-5fe60c87992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for box plot visualization\n",
    "job_ratings = df_filtered[df_filtered['Job Title'].str.contains('Data Scientist|Data Analyst', case=False, na=False)]\n",
    "\n",
    "# Box plot of Rating by job title\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.boxplot(x='Job Title', y='Rating', data=df_filtered)\n",
    "plt.title('Ratings by Job Title')\n",
    "plt.xlabel('Job Title')\n",
    "plt.ylabel('Company Rating')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b333046-3579-41dc-aa32-bbf9069e898a",
   "metadata": {},
   "source": [
    "The box plot shows the distribution of company ratings across all Data Scientist and Data Analyst jobs. Both roles have a similar distribution of ratings with the mean rating around 3.8. This indicates that companies hiring for these rols generally have good ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7168972-dd3f-48bb-bf9d-580a59fad3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot of ratings by state\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(x='State', y='Rating', data=df_filtered)\n",
    "plt.title('Company Ratings by State')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Company Rating')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33f79c2-751a-4f26-8118-612d68f5b368",
   "metadata": {},
   "source": [
    "The box plot shows the distribution of company ratings across all states with Data Scientist and Data Analyst roles available. Most states have median ratings of 3.5 to 4.1, indicating generally positive company ratings across the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a678a1b-8806-4808-a567-ef86d05260f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each industry\n",
    "industry_counts = df_filtered['Industry'].value_counts()\n",
    "\n",
    "# Filter for the top 10 industries\n",
    "top_10_industries = industry_counts.head(10).index\n",
    "\n",
    "# Filter the dataframe to include only rows from the top 10 industries\n",
    "df_top_10_industries = df_filtered[df_filtered['Industry'].isin(top_10_industries)]\n",
    "\n",
    "# Display the filtered dataframe with the top 10 industries\n",
    "df_top_10_industries[['Industry']].head()\n",
    "\n",
    "# Box plot of ratings by top industries\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Industry', y='Rating', data=df_top_10_industries)\n",
    "plt.title('Company Ratings by Industry')\n",
    "plt.xlabel('Industry')\n",
    "plt.ylabel('Company Rating')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee8b24-e086-4b91-bf54-d5a413bb3759",
   "metadata": {},
   "source": [
    "The box plot shows the distribution of company ratings across the top 10 industries. Most industries have median ratings around 3.8 to 4.0, with some variability in the distribution. This indicates that while most industries maintain good company ratings, there are some differences in the spread of these ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe56b0-ceb8-4726-aa58-06fbcc24bc3a",
   "metadata": {},
   "source": [
    "<b>Most In-Demand Skills:</b><br>\n",
    "<b>Top Skills:</b> Analytics, Machine learning, Analysis, AI, Modeling, Python, Statistics, Statistical analysis, AWS, SQL, Data visualization, SAS, Data analysis, Tableau, Data mining.<br>\n",
    "These skills are critical for candidates looking to secure a Data Scientist or Data Analyst position.<br><br>\n",
    "<b>Top Locations for Jobs:</b><br>\n",
    "<b>Top Locations:</b> Major states with tech hubs have the most job opportunities.<br>\n",
    "Visualization shows the distribution of these jobs across each state.<br><br>\n",
    "<b>Top Industries Hiring:</b><br>\n",
    "<b>Key Industries:</b> Information Technology, Finance, Healthcare, Enterprise Software & Network Solutions, and Aerospace & Defense.\n",
    "Visualization shows the distribution of these jobs across various industries.<br><br>\n",
    "<b>Data Relationships:</b><br>\n",
    "<b>Scatter Plot:</b> Weak positive correlation between average salary estimates and industry.<br>\n",
    "<b>Box Plots:</b> Similar distributions of company ratings across job titles, locations, and industries.<br><br>\n",
    "<b>Feature Engineering:</b><br>\n",
    "Categorical features have been one-hot encoded.<br>\n",
    "Numerical features have been standardized.<br><br>\n",
    "<b>Recommendations</b><br>\n",
    "<b>1. Skill Development:</b> Prioritize learning Machine learning, Analytics, Python, Statistics, SQL, and Data visualization. These are the some of the most frequently mentioned skills in job descriptions.<br>\n",
    "<b>2. Targeted Job Search:</b> Focus on the top locations and industries identified. This will increase the efficiency of your job search<br>\n",
    "<b>3. Continuous Analysis:</b> Regularly update the analysis to capture trends and changes in the job market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12056497-c3ef-473a-bea7-d9f4bfadd8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all unique skills from the 'Extracted Skills' column\n",
    "unique_skills = set(skill for skills_list in df_filtered['Extracted Skills'].dropna().str.split(', ') for skill in skills_list)\n",
    "\n",
    "# Create binary columns for each skill (multi-label target)\n",
    "for skill in unique_skills:\n",
    "    df_filtered[f'Target_{skill}'] = df_filtered['Extracted Skills'].apply(lambda x: 1 if skill in x else 0)\n",
    "\n",
    "# Define the target variables (multi-label format)\n",
    "y = df_filtered[[f'Target_{skill}' for skill in unique_skills]]\n",
    "\n",
    "# Check and remove skills that only have one class (all 0s or all 1s)\n",
    "valid_skills = [col for col in y.columns if y[col].nunique() > 1]\n",
    "\n",
    "# Filter the target dataframe to only include valid skills (with both 0s and 1s)\n",
    "y_valid = y[valid_skills]\n",
    "\n",
    "# Define features (e.g., 'Rating', 'State', 'Industry')\n",
    "X = df_filtered[['Rating', 'State', 'Industry']]\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X_encoded = pd.get_dummies(X, columns=['State', 'Industry'], drop_first=True)\n",
    "\n",
    "# Handle missing values in 'Rating' by filling with the mean\n",
    "X_encoded['Rating'].fillna(X_encoded['Rating'].mean(), inplace=True)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_valid, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a963f92-464e-41ac-99d9-436d0d590771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier with label encoding\n",
    "# Instantiate the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Wrap it in MultiOutputClassifier to handle multi-label classification\n",
    "multi_rf_model = MultiOutputClassifier(rf_model, n_jobs=-1)\n",
    "\n",
    "# Train the Random Forest model on the training data\n",
    "multi_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for each skill on the test set\n",
    "y_pred_rf = multi_rf_model.predict(X_test)\n",
    "\n",
    "# Initialize dictionaries to store the evaluation metrics for each skill\n",
    "rf_evaluation_metrics = {\n",
    "    'Skill': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1 Score': [],\n",
    "    'Confusion Matrix': []\n",
    "}\n",
    "\n",
    "# Loop through each skill (target column) to compute the metrics\n",
    "for skill in valid_skills:\n",
    "    y_pred_skill_rf = y_pred_rf[:, y_valid.columns.get_loc(skill)]\n",
    "    y_true_skill_rf = y_test[skill].values\n",
    "    \n",
    "    acc_rf = accuracy_score(y_true_skill_rf, y_pred_skill_rf)\n",
    "    precision_rf = precision_score(y_true_skill_rf, y_pred_skill_rf, zero_division=0)\n",
    "    recall_rf = recall_score(y_true_skill_rf, y_pred_skill_rf, zero_division=0)\n",
    "    f1_rf = f1_score(y_true_skill_rf, y_pred_skill_rf, zero_division=0)\n",
    "    cm_rf = confusion_matrix(y_true_skill_rf, y_pred_skill_rf)\n",
    "    \n",
    "    # Store the metrics\n",
    "    rf_evaluation_metrics['Skill'].append(skill)\n",
    "    rf_evaluation_metrics['Accuracy'].append(acc_rf)\n",
    "    rf_evaluation_metrics['Precision'].append(precision_rf)\n",
    "    rf_evaluation_metrics['Recall'].append(recall_rf)\n",
    "    rf_evaluation_metrics['F1 Score'].append(f1_rf)\n",
    "    rf_evaluation_metrics['Confusion Matrix'].append(cm_rf)\n",
    "\n",
    "# Convert the metrics dictionary to a DataFrame for easy viewing\n",
    "rf_evaluation_df = pd.DataFrame(rf_evaluation_metrics)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(rf_evaluation_df[['Skill', 'Accuracy', 'Precision', 'Recall', 'F1 Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45dbb7-fe32-450f-93ee-dbc027d66375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use class_weight='balanced' to help with the imbalanced classes.\n",
    "# Instantiate the Random Forest model with class_weight='balanced'\n",
    "rf_model_balanced = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Wrap it in MultiOutputClassifier to handle multi-label classification\n",
    "multi_rf_model_balanced = MultiOutputClassifier(rf_model_balanced, n_jobs=-1)\n",
    "\n",
    "# Train the Random Forest model on the training data\n",
    "multi_rf_model_balanced.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for each skill on the test set\n",
    "y_pred_rf_balanced = multi_rf_model_balanced.predict(X_test)\n",
    "\n",
    "# Initialize a dictionary to store the evaluation metrics\n",
    "rf_evaluation_metrics = {\n",
    "    'Skill': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1 Score': [],\n",
    "    'Confusion Matrix': []\n",
    "}\n",
    "\n",
    "# Loop through each skill (target column) to compute the metrics\n",
    "valid_skills = y_train.columns  # Assuming your y_train DataFrame contains skill names as columns\n",
    "for skill in valid_skills:\n",
    "    y_pred_skill_rf = y_pred_rf_balanced[:, y_test.columns.get_loc(skill)]\n",
    "    y_true_skill_rf = y_test[skill].values\n",
    "    \n",
    "    # Calculate metrics for the current skill\n",
    "    acc_rf = accuracy_score(y_true_skill_rf, y_pred_skill_rf)\n",
    "    precision_rf = precision_score(y_true_skill_rf, y_pred_skill_rf, zero_division=0)\n",
    "    recall_rf = recall_score(y_true_skill_rf, y_pred_skill_rf, zero_division=0)\n",
    "    f1_rf = f1_score(y_true_skill_rf, y_pred_skill_rf, zero_division=0)\n",
    "    cm_rf = confusion_matrix(y_true_skill_rf, y_pred_skill_rf)\n",
    "    \n",
    "    # Store the metrics in the dictionary\n",
    "    rf_evaluation_metrics['Skill'].append(skill)\n",
    "    rf_evaluation_metrics['Accuracy'].append(acc_rf)\n",
    "    rf_evaluation_metrics['Precision'].append(precision_rf)\n",
    "    rf_evaluation_metrics['Recall'].append(recall_rf)\n",
    "    rf_evaluation_metrics['F1 Score'].append(f1_rf)\n",
    "    rf_evaluation_metrics['Confusion Matrix'].append(cm_rf)\n",
    "\n",
    "# Convert the metrics dictionary to a DataFrame for easy viewing\n",
    "rf_evaluation_df = pd.DataFrame(rf_evaluation_metrics)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(rf_evaluation_df[['Skill', 'Accuracy', 'Precision', 'Recall', 'F1 Score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7312fd-012d-4c10-922a-71e12395fb71",
   "metadata": {},
   "source": [
    "<h3>Conclusion:</h3>\n",
    "The tuned Random Forest model with class balancing generally shows improvements in recall and F1 scores, particularly for difficult-to-predict classes. The accuracy remains stable overall. However, precision dropped for a few cases, possibly due to the class balancing leading to more false positives. The model performed better for skills like Target_Spark, Target_NLP, and Target_Data Mining, but it still struggles with certain skills like Target_Azure, Target_Keras, and Target_Power BI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c95550e-9dcf-4397-ade2-45a19233ffab",
   "metadata": {},
   "source": [
    "<h3>Summary of all 3 models:</h3>\n",
    "\n",
    "<b>Logistic Regression:</b> Best for environments where simplicity, speed, and interpretability are critical, but it does not perform well for complex, non-linear problems.\n",
    "\n",
    "<b>Random Forest:</b> A strong middle ground, offering good performance for a wide variety of tasks while being more scalable and efficient than the stacked model. It balances complexity and predictive power, making it a good general-purpose model, especially when computational resources are available.\n",
    "\n",
    "<b>Stacked Model (LightGBM + XGBoost):</b> Best for extracting maximum performance in complex problems, particularly for tasks like Deep Learning and Machine Learning where it showed improvement. However, the high computational cost and maintenance requirements make it suitable for environments with abundant computational resources and the ability to handle model complexity.\n",
    "\n",
    "<h3>Recommendation:</h3>\n",
    "\n",
    "For most use cases, especially where performance and computational efficiency are both important, **Random Forest** is the best overall option. It provides a good balance of performance, scalability, and maintenance cost.\n",
    "**Stacked Model** is preferable when the highest predictive accuracy is required, particularly for complex non-linear problems, and when computational resources and time for tuning are not limiting factors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
